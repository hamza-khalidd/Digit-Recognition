{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Importing All Relevant Libraries\n",
    "# ===============================================================================\n",
    "import pandas as pd # For Dataframe Working\n",
    "import scipy \n",
    "from scipy import signal # For Convolution\n",
    "import numpy as np # For Array and Matrix\n",
    "from sklearn.model_selection import train_test_split # For Splitting Data\n",
    "from sklearn import metrics # For Accuracy\n",
    "from sklearn import svm # For SVM Model\n",
    "from sklearn.neighbors import KNeighborsClassifier # For KNN Model\n",
    "from sklearn.naive_bayes import MultinomialNB # For Multinomial Naive Bayes Model\n",
    "from sklearn import tree # For Decision Tree Model\n",
    "from sklearn.model_selection import cross_val_score # For Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Training Data Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Import training data named as train\n",
    "# ===============================================================================\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Variables For Splitting The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  dataX : All training data rows and columns except label column (target)\n",
    "#  dataY : Only label column (target)\n",
    "# ===============================================================================\n",
    "dataX = train.drop(columns=['label'])\n",
    "dataY = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Convolution Filters (Incremental & all 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Make filters to pass in scipy.signal.convolve2d function for Convolution\n",
    "#  filterArr5 : 5x5 Filter containing all 1's in its array\n",
    "#  filterArrInc5 : 5x5 Filter containing Increment at each level in its array\n",
    "#  filterArr7 : 7x7 Filter containing all 1's in its array\n",
    "#  filterArrInc7 : 7x7 Filter containing Increment at each level in its array\n",
    "#  filterArr9 : 9x9 Filter containing all 1's in its array\n",
    "#  filterArrInc9 : 9x9 Filter containing Increment at each level in its array\n",
    "# ===============================================================================\n",
    "\n",
    "filterArr3 = np.array([[1,1,1],\n",
    "                       [1,2,1],\n",
    "                       [1,1,1]])\n",
    "\n",
    "filterArrInc3 = np.array([[1,1,1],\n",
    "                         [1,2,1],\n",
    "                         [1,1,1]])\n",
    "\n",
    "# ===============================================================================\n",
    "filterArr5 = np.array([[1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1],\n",
    "                      [1,1,1,1,1]])\n",
    "\n",
    "filterArrInc5 = np.array([[1,1,1,1,1],\n",
    "                         [1,2,2,2,1],\n",
    "                         [1,2,3,2,1],\n",
    "                         [1,2,2,2,1],\n",
    "                         [1,1,1,1,1]])\n",
    "\n",
    "# ===============================================================================\n",
    "filterArr7 = np.array([[1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1]])\n",
    "\n",
    "filterArrInc7 = np.array([[1,1,1,1,1,1,1],\n",
    "                         [1,2,2,2,2,2,1],\n",
    "                         [1,2,3,3,3,2,1],\n",
    "                         [1,2,3,4,3,2,1],\n",
    "                         [1,2,3,3,3,2,1],\n",
    "                         [1,2,2,2,2,2,1],\n",
    "                         [1,1,1,1,1,1,1]])\n",
    "\n",
    "# ===============================================================================\n",
    "filterArr9 = np.array([[1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1],\n",
    "                      [1,1,1,1,1,1,1,1,1]])\n",
    "\n",
    "filterArrInc9 = np.array([[1,1,1,1,1,1,1,1,1],\n",
    "                         [1,2,2,2,2,2,2,2,1],\n",
    "                         [1,2,3,3,3,3,3,2,1],\n",
    "                         [1,2,3,4,4,4,3,2,1],\n",
    "                         [1,2,3,4,5,4,3,2,1],\n",
    "                         [1,2,3,4,4,4,3,2,1],\n",
    "                         [1,2,3,3,3,3,3,2,1],\n",
    "                         [1,2,2,2,2,2,2,2,1],\n",
    "                         [1,1,1,1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x3 Filters Shape Check\n",
      "(3, 3)\n",
      "(3, 3)\n",
      "5x5 Filters Shape Check\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "7x7 Filters Shape Check\n",
      "(7, 7)\n",
      "(7, 7)\n",
      "9x9 Filters Shape Check\n",
      "(9, 9)\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Printing shape of Filters to veriy if any mishap happened or not.\n",
    "# ===============================================================================\n",
    "print('3x3 Filters Shape Check')\n",
    "print(filterArr3.shape)\n",
    "print(filterArrInc3.shape)\n",
    "print('5x5 Filters Shape Check')\n",
    "print(filterArr5.shape)\n",
    "print(filterArrInc5.shape)\n",
    "print('7x7 Filters Shape Check')\n",
    "print(filterArr7.shape)\n",
    "print(filterArrInc7.shape)\n",
    "print('9x9 Filters Shape Check')\n",
    "print(filterArr9.shape)\n",
    "print(filterArrInc9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Creating an empty dataframe named df which contains/store convolution data\n",
    "# ===============================================================================\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Printing dataframe\n",
    "# ===============================================================================\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting DataFrame Into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "#  Converts dataframe of training data except the target variable which is label\n",
    "#  into an array named arr.\n",
    "# ===============================================================================\n",
    "arr = np.asarray(dataX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Convolution & Creating New DataFrame With Convolved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# xRes = np.reshape(arr[i],(-1,28)) : This line of code is used to reshape \n",
    "#        indexes of array one by one into 2d array (Each index of array refers\n",
    "#        1 iimage data).\n",
    "#       --------------------------------------------------------------------\n",
    "# x = scipy.signal.convolve2d(xRes, filterArrInc5, mode='valid') : This means\n",
    "#     that we have taken convolve2d function from scipy.signal and passed total\n",
    "#     3 arguments:\n",
    "#     --> xRes : aur 2d array (of 1 image data).\n",
    "#     --> filterArr5 : this is our filters what we created above.\n",
    "#     --> mode : This is valid mode which returns the sum of 5x5 matrix and \n",
    "#                traverse the whole 2d array for convolution.\n",
    "#       --------------------------------------------------------------------\n",
    "# array_1d = ax.flatten() : We copy our convolved 2d array from x variable\n",
    "#           and place it into ax and the flatten our 2d array into 1d and saved \n",
    "#           in array_1d.\n",
    "#       --------------------------------------------------------------------\n",
    "# df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) : This means that\n",
    "#      I append each an evey flatten 1d array into dataframe then Transpose it \n",
    "#      because Transpose it appends into 1 column but we needed 1 image into 1 \n",
    "#      row, so I use Transpose here.\n",
    "#       --------------------------------------------------------------------\n",
    "# This complete code will run in a loop till the range of total rows (42000),\n",
    "# taking images data (row wise) one by one and then convert them into 2d array\n",
    "# and convolve them, then flatten into 1d and append into dataframe.\n",
    "# ===============================================================================\n",
    "\n",
    "for i in range(0,42000):\n",
    "    x = None\n",
    "    ax = None\n",
    "    xRes = None\n",
    "    array_1d = None\n",
    "    \n",
    "    xRes = np.reshape(arr[i],(-1,28))\n",
    "    x = scipy.signal.convolve2d(xRes, filterArrInc3, mode='valid')\n",
    "    ax = x\n",
    "    array_1d = ax.flatten()\n",
    "    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of Convolved Data and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 676)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# df.shape : Print the shape of data means total rows and columns where df\n",
    "#            is new dataframe of convolution data. (Rows=42000, Columns=576)\n",
    "#            -------------------------------------------------------------------\n",
    "# dataY.shape : Print the shape of data means total rows and columns where dataY\n",
    "#               is dataframe of target data. (Rows=42000, Columns=1)\n",
    "# ===============================================================================\n",
    "print(df.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>666</th>\n",
       "      <th>667</th>\n",
       "      <th>668</th>\n",
       "      <th>669</th>\n",
       "      <th>670</th>\n",
       "      <th>671</th>\n",
       "      <th>672</th>\n",
       "      <th>673</th>\n",
       "      <th>674</th>\n",
       "      <th>675</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>309</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 676 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  666  667  668  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "41995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "41996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "41997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "41998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "41999    0    0    0    0    0    0    0    0    0    0  ...  309   59    0   \n",
       "\n",
       "       669  670  671  672  673  674  675  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "41995    0    0    0    0    0    0    0  \n",
       "41996    0    0    0    0    0    0    0  \n",
       "41997    0    0    0    0    0    0    0  \n",
       "41998    0    0    0    0    0    0    0  \n",
       "41999    0    0    0    0    0    0    0  \n",
       "\n",
       "[42000 rows x 676 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # Printing dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# This Cell Description\n",
    "# ================================================================================\n",
    "# Filename of 3x3 Convolution Data on all 1 Filter : train-3x3-Nor-Filt.csv\n",
    "# Filename of 3x3 Convolution Data on Incremental Filter : train-3x3-Inc-Filt.csv\n",
    "# ================================================================================\n",
    "# Filename of 5x5 Convolution Data on all 1 Filter : train-5x5-Nor-Filt.csv\n",
    "# Filename of 5x5 Convolution Data on Incremental Filter : train-5x5-Inc-Filt.csv\n",
    "# ================================================================================\n",
    "# Filename of 7x7 Convolution Data on all 1 Filter : train-7x7-Nor-Filt.csv\n",
    "# Filename of 7x7 Convolution Data on Incremental Filter : train-7x7-Inc-Filt.csv\n",
    "# ================================================================================\n",
    "# Filename of 9x9 Convolution Data on all 1 Filter : train-9x9-Nor-Filt.csv\n",
    "# Filename of 9x9 Convolution Data on Incremental Filter : train-9x9-Inc-Filt.csv\n",
    "# ================================================================================\n",
    "df.to_csv('train-3x3-Inc-Filt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3x3 Convolution Data (Normal Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 3x3 Convoled Data\n",
    "# ===============================================================================\n",
    "train3x3 = pd.read_csv('train-3x3-Nor-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 3x3 Normal Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train3x3, dataY, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 676)\n",
      "xtest shape  :  (8400, 676)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "98.20238095238095\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "97.5\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "87.85714285714286\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "80.57142857142857\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 3x3 Convolution - Normal Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.982024\n",
      "1                       KNN  0.975000\n",
      "2             Decision Tree  0.878571\n",
      "3  Multinomial Naives Bayes  0.805714\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 3x3 Convolution - Normal Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.972321\n",
      "1           KNN              0.969881\n",
      "2      Dec Tree              0.862857\n",
      "3  Naives Bayes              0.806548\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 3x3 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 3x3 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3x3 Convolution Data (Incremental Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 3x3 Convoled Data\n",
    "# ===============================================================================\n",
    "train3x3Inc = pd.read_csv('train-3x3-Inc-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 3x3 Incremental Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train3x3Inc, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 676)\n",
      "xtest shape  :  (8400, 676)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "98.20238095238095\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "97.5\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "88.19047619047619\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "80.57142857142857\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 3x3 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.982024\n",
      "1                       KNN  0.975000\n",
      "2             Decision Tree  0.881905\n",
      "3  Multinomial Naives Bayes  0.805714\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 3x3 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.972321\n",
      "1           KNN              0.969881\n",
      "2      Dec Tree              0.864196\n",
      "3  Naives Bayes              0.806548\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 3x3 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 3x3 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x5 Convolution Data (Normal Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 5x5 Convoled Data\n",
    "# ===============================================================================\n",
    "train5x5 = pd.read_csv('train-5x5-Nor-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 576)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Shape of Imported Data(rows,columns)\n",
    "# ===============================================================================\n",
    "train5x5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>573</th>\n",
       "      <th>574</th>\n",
       "      <th>575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>185</td>\n",
       "      <td>322</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>435</td>\n",
       "      <td>180</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>316</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>401</td>\n",
       "      <td>661</td>\n",
       "      <td>661</td>\n",
       "      <td>661</td>\n",
       "      <td>655</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>156</td>\n",
       "      <td>311</td>\n",
       "      <td>565</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>382</td>\n",
       "      <td>223</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5   6    7    8    9  ...  566  567  568  569  570  571  \\\n",
       "0  0  0  0  0  0  0   0    0    0    0  ...    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  18   48  185  322  ...  689  435  180   34   15    0   \n",
       "2  0  0  0  0  0  0   0    0    3  144  ...  316   62    0    0    0    0   \n",
       "3  0  0  0  0  0  0   0    0    0    0  ...    0    6  401  661  661  661   \n",
       "4  0  0  0  0  0  1  26  156  311  565  ...  635  382  223   94    4    0   \n",
       "\n",
       "   572  573  574  575  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3  655  260    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 576 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing starting 5 rows of dataset.\n",
    "# ===============================================================================\n",
    "train5x5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 5x5 Normal Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train5x5, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 576)\n",
      "xtest shape  :  (8400, 576)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "98.01190476190477\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "96.67857142857143\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "87.01190476190476\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "76.73809523809524\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 5x5 Convolution - Normal Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.980119\n",
      "1                       KNN  0.966786\n",
      "2             Decision Tree  0.870119\n",
      "3  Multinomial Naives Bayes  0.767381\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 5x5 Convolution - Normal Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.966815\n",
      "1           KNN              0.961458\n",
      "2      Dec Tree              0.861875\n",
      "3  Naives Bayes              0.764613\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 5x5 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 5x5 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x5 Convolution Data (Incremental Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 5x5 Convoled Data\n",
    "# ===============================================================================\n",
    "train5x5Inc = pd.read_csv('train-5x5-Inc-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 576)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train5x5Inc.shape # Shape of impoted data (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>566</th>\n",
       "      <th>567</th>\n",
       "      <th>568</th>\n",
       "      <th>569</th>\n",
       "      <th>570</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>573</th>\n",
       "      <th>574</th>\n",
       "      <th>575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>185</td>\n",
       "      <td>322</td>\n",
       "      <td>...</td>\n",
       "      <td>689</td>\n",
       "      <td>435</td>\n",
       "      <td>180</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>316</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>407</td>\n",
       "      <td>876</td>\n",
       "      <td>977</td>\n",
       "      <td>971</td>\n",
       "      <td>756</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>156</td>\n",
       "      <td>311</td>\n",
       "      <td>565</td>\n",
       "      <td>...</td>\n",
       "      <td>635</td>\n",
       "      <td>382</td>\n",
       "      <td>223</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5   6    7    8    9  ...  566  567  568  569  570  571  \\\n",
       "0  0  0  0  0  0  0   0    0    0    0  ...    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  18   48  185  322  ...  689  435  180   34   15    0   \n",
       "2  0  0  0  0  0  0   0    0    3  144  ...  316   62    0    0    0    0   \n",
       "3  0  0  0  0  0  0   0    0    0    0  ...    0    6  407  876  977  971   \n",
       "4  0  0  0  0  0  1  26  156  311  565  ...  635  382  223   94    4    0   \n",
       "\n",
       "   572  573  574  575  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3  756  260    0    0  \n",
       "4    0    0    0    0  \n",
       "\n",
       "[5 rows x 576 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train5x5Inc.head() # printing starting 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 5x5 Incremental Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train5x5Inc, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 576)\n",
      "xtest shape  :  (8400, 576)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "98.05952380952381\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "97.05952380952381\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "87.98809523809524\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "77.66666666666666\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 5x5 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.980595\n",
      "1                       KNN  0.970595\n",
      "2             Decision Tree  0.879881\n",
      "3  Multinomial Naives Bayes  0.776667\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 5x5 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.969226\n",
      "1           KNN              0.965565\n",
      "2      Dec Tree              0.863810\n",
      "3  Naives Bayes              0.776042\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 5x5 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 5x5 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7x7 Convolution Data (Normal Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 7x7 Convoled Data\n",
    "# ===============================================================================\n",
    "train7x7 = pd.read_csv('train-7x7-Nor-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 484)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing shape of imported data\n",
    "# ===============================================================================\n",
    "train7x7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 7x7 Normal Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train7x7, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 484)\n",
      "xtest shape  :  (8400, 484)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "97.41666666666666\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "95.04761904761905\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "84.77380952380953\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "71.79761904761904\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 7x7 Convolution - Normal Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.974167\n",
      "1                       KNN  0.950476\n",
      "2             Decision Tree  0.847738\n",
      "3  Multinomial Naives Bayes  0.717976\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 7x7 Convolution - Normal Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.956667\n",
      "1           KNN              0.940744\n",
      "2      Dec Tree              0.832946\n",
      "3  Naives Bayes              0.712143\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 7x7 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 7x7 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7x7 Convolution Data (Incremental Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 7x7 Convoled Data\n",
    "# ===============================================================================\n",
    "train7x7Inc = pd.read_csv('train-7x7-Inc-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 484)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing rows and columns of imported data\n",
    "# ===============================================================================\n",
    "train7x7Inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train7x7Inc is the data for training returned after\n",
    "#  Convolution by 3x3 Incremental Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train7x7Inc, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 484)\n",
      "xtest shape  :  (8400, 484)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "97.73809523809524\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "96.0952380952381\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "86.64285714285714\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "74.28571428571429\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 7x7 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.977381\n",
      "1                       KNN  0.960952\n",
      "2             Decision Tree  0.866429\n",
      "3  Multinomial Naives Bayes  0.742857\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 7x7 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.963006\n",
      "1           KNN              0.953750\n",
      "2      Dec Tree              0.848929\n",
      "3  Naives Bayes              0.737024\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 7x7 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 7x7 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9x9 Convolution Data (Normal Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 9x9 Convoled Data\n",
    "# ===============================================================================\n",
    "train9x9 = pd.read_csv('train-9x9-Nor-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 400)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train9x9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train9x9 is the data for training returned after\n",
    "#  Convolution by 9x9 Normal Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train9x9, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 400)\n",
      "xtest shape  :  (8400, 400)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Sizes of Testing and Training Data (Afer Split)\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "96.55952380952381\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "92.41666666666667\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "81.47619047619048\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "68.15476190476191\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 9x9 Convolution - Normal Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.965595\n",
      "1                       KNN  0.924167\n",
      "2             Decision Tree  0.814762\n",
      "3  Multinomial Naives Bayes  0.681548\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 9x9 Convolution - Normal Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.942202\n",
      "1           KNN              0.915833\n",
      "2      Dec Tree              0.795655\n",
      "3  Naives Bayes              0.677143\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 9x9 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 9x9 Convolution - Normal Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9x9 Convolution Data (Incremental Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Importing 9x9 Convoled Data\n",
    "# ===============================================================================\n",
    "train9x9Inc = pd.read_csv('train-9x9-Inc-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 400)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing Shape of Imported Data\n",
    "# ===============================================================================\n",
    "train9x9Inc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train9x9Inc is the data for training returned after\n",
    "#  Convolution by 3x3 Incremental Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train9x9Inc, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape :  (33600, 400)\n",
      "xtest shape  :  (8400, 400)\n",
      "ytrain shape :  (33600,)\n",
      "ytest shape  :  (8400,)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Print Sizes of Train and Test Data\n",
    "# ===============================================================================\n",
    "print(\"xtrain shape : \", xtrain.shape) \n",
    "print(\"xtest shape  : \", xtest.shape) \n",
    "print(\"ytrain shape : \", ytrain.shape) \n",
    "print(\"ytest shape  : \", ytest.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n",
      "97.35714285714285\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : KNN\n",
      "============================================================\n",
      "94.17857142857143\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Decision Tree\n",
      "============================================================\n",
      "83.89285714285715\n",
      "============================================================\n",
      "Machine Learning Model (Accuracy) : Multinomial Naive Bayes\n",
      "============================================================\n",
      "71.30952380952381\n"
     ]
    }
   ],
   "source": [
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10) # Initializing SVM\n",
    "svc_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "svcPred = svc_clf.predict(xtest) # Predicting Data\n",
    "svcAcc = metrics.accuracy_score(ytest, svcPred) # Accuracy Score\n",
    "print(svcAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : KNN')\n",
    "print('============================================================')\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "result=knn_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "knnPred = knn_clf.predict(xtest) # Predicting Data\n",
    "knnAcc = metrics.accuracy_score(ytest, knnPred) # Accuracy Score\n",
    "print (knnAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Decision Tree')\n",
    "print('============================================================')\n",
    "dt_clf = tree.DecisionTreeClassifier() # Initialzing Decision Tree Classifier\n",
    "result = dt_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "dtPred = dt_clf.predict(xtest) # Predicting Data\n",
    "dtAcc = metrics.accuracy_score(ytest, dtPred) # Accuracy Score\n",
    "print (dtAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : Multinomial Naive Bayes')\n",
    "print('============================================================')\n",
    "mnb_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "res = mnb_clf.fit(xtrain, ytrain) # Fitting Model According to Training Data\n",
    "mnbPred = mnb_clf.predict(xtest) # Predicting Data\n",
    "mnbAcc = metrics.accuracy_score(ytest, mnbPred) # Accuracy Score\n",
    "print (mnbAcc*100) # *100 to clarify more like (e.g : 0.971 --> 97.1)\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': [ 'SVC', 'KNN', 'Decision Tree', 'Multinomial Naives Bayes'], \n",
    "    'Accuracy': [svcAcc, knnAcc, dtAcc,  mnbAcc]} # Creating Dictionary\n",
    "\n",
    "resDF = pd.DataFrame(data=d) # Converting Dictionary Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "# SVC\n",
    "svc_clf = svm.SVC() # Initializing SVM\n",
    "svc_scores = cross_val_score(svc_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing SVM Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "svc_mean = svc_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier() # Initializing KNN\n",
    "knn_scores = cross_val_score(knn_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing KNN Classifier -\n",
    "# - and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "knn_mean = knn_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier() # Initializing Decision Tree\n",
    "tree_scores = cross_val_score(tree_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Decision Tree-\n",
    "# - Classifier and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "tree_mean = tree_scores.mean() # Mean of calculated scores\n",
    "\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = MultinomialNB() # Initializing Multinomial Naive Bayes\n",
    "nav_scores = cross_val_score(nav_clf, xtrain, ytrain, cv=3) # Initializing Cross Validation By Passing Multinomial -\n",
    "# - Naive Bayes and  xtrain and ytrain data with cv = 3 which is Cross Validation Iteration.\n",
    "nav_mean =nav_scores.mean() # Mean of calculated scores\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "cvD = {'Classifiers': [ 'SVC', 'KNN', 'Dec Tree', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [svc_mean, knn_mean, tree_mean,  nav_mean]} # Creating Dictionary of Mean Scores\n",
    "\n",
    "crossVal_df = pd.DataFrame(data=cvD) # Converting Dictionary Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Accuracy of All Modals Applied On : 9x9 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "                Classifiers  Accuracy\n",
      "0                       SVC  0.973571\n",
      "1                       KNN  0.941786\n",
      "2             Decision Tree  0.838929\n",
      "3  Multinomial Naives Bayes  0.713095\n",
      "================================================================================\n",
      "Cross Validation of All Modals Applied On : 9x9 Convolution - Incremental Filter\n",
      "================================================================================\n",
      "    Classifiers  Crossval Mean Scores\n",
      "0           SVC              0.952917\n",
      "1           KNN              0.935238\n",
      "2      Dec Tree              0.819226\n",
      "3  Naives Bayes              0.707411\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame of Accuracy of All Models & DataFrame of Cross Validated \n",
    "# Mean Scores of All Models\n",
    "# ===============================================================================\n",
    "print('================================================================================')\n",
    "print('Accuracy of All Modals Applied On : 9x9 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(resDF)\n",
    "print('================================================================================')\n",
    "print('Cross Validation of All Modals Applied On : 9x9 Convolution - Incremental Filter')\n",
    "print('================================================================================')\n",
    "print(crossVal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data Predictions (Using SVM On 3x3 Convolution - Incremental Filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 98.20238095238095 Accuracy On 3x3 Convolution Incremental Filter (Via SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Import testing data to make predictions on it for submission\n",
    "# ===============================================================================\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# printing shape (rows, columns) of testing data\n",
    "# ===============================================================================\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# converting test dataframe into 1d array for Convolution\n",
    "# ===============================================================================\n",
    "arr = np.asarray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Type of arr (Numpy Array)\n",
    "# ===============================================================================\n",
    "type(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# xRes = np.reshape(arr[i],(-1,28)) : This line of code is used to reshape \n",
    "#        indexes of array one by one into 2d array (Each index of array refers\n",
    "#        1 iimage data).\n",
    "#       --------------------------------------------------------------------\n",
    "# x = scipy.signal.convolve2d(xRes, filterArrInc5, mode='valid') : This means\n",
    "#     that we have taken convolve2d function from scipy.signal and passed total\n",
    "#     3 arguments:\n",
    "#     --> xRes : aur 2d array (of 1 image data).\n",
    "#     --> filterArr5 : this is our filters what we created above.\n",
    "#     --> mode : This is valid mode which returns the sum of 5x5 matrix and \n",
    "#                traverse the whole 2d array for convolution.\n",
    "#       --------------------------------------------------------------------\n",
    "# array_1d = ax.flatten() : We copy our convolved 2d array from x variable\n",
    "#           and place it into ax and the flatten our 2d array into 1d and saved \n",
    "#           in array_1d.\n",
    "#       --------------------------------------------------------------------\n",
    "# df = df.append(pd.DataFrame(array_1d).T, ignore_index=True) : This means that\n",
    "#      I append each an evey flatten 1d array into dataframe then Transpose it \n",
    "#      because Transpose it appends into 1 column but we needed 1 image into 1 \n",
    "#      row, so I use Transpose here.\n",
    "#       --------------------------------------------------------------------\n",
    "# This complete code will run in a loop till the range of total rows (28000),\n",
    "# taking images data (row wise) one by one and then convert them into 2d array\n",
    "# and convolve them, then flatten into 1d and append into dataframe.\n",
    "# ===============================================================================\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(0, len(arr)):\n",
    "    x = None\n",
    "    ax = None\n",
    "    xRes = None\n",
    "    array_1d = None\n",
    "    \n",
    "    xRes = np.reshape(arr[i],(-1,28))\n",
    "    x = scipy.signal.convolve2d(xRes, filterArrInc3, mode='valid')\n",
    "    ax = x\n",
    "    array_1d = ax.flatten()\n",
    "    df = df.append(pd.DataFrame(array_1d).T, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 676)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# printing dataframe shape (rows, columns)\n",
    "# ===============================================================================\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Import 3x3 Training Data (Returned After Convolution) for training purpose\n",
    "# ===============================================================================\n",
    "train3x3Inc = pd.read_csv('train-3x3-Inc-Filt.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Splitting data : Where train3x3Inc is the data for training returned after\n",
    "#  Convolution by 3x3 Incremental Filter.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  dataY = This is the target variable or label column from dataset.\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  test_size : percentage of splitting data into 0.2 or 20% ratio\n",
    "#  ---------------------------------------------------------------------------\n",
    "#  random_state : This is a random generator if you set it it will randomly\n",
    "#               split according to that seed otherwise if you dont use this, it\n",
    "#               will split randomly each different time\n",
    "# ===============================================================================\n",
    "xtrain , xtest , ytrain, ytest = train_test_split(train3x3Inc, dataY, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Machine Learning Model (Accuracy) : SVM\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Fitting data into SVM Model for data training.\n",
    "# ===============================================================================\n",
    "print('============================================================')\n",
    "print('Machine Learning Model (Accuracy) : SVM')\n",
    "print('============================================================')\n",
    "svc_clf = svm.SVC(kernel=\"rbf\", C=10)\n",
    "svc_clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Predicting dataframe which we get in return after 3x3 Convolution on \n",
    "# Incremental Filter.\n",
    "# ===============================================================================\n",
    "test_svm_pred = svc_clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing length of predicted data (Just For Verification)\n",
    "# ===============================================================================\n",
    "len(test_svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Creating a new dataframe with two different columns in which one will contain\n",
    "# ImageId (Serial No.), and other will be Label which contain predicted values.\n",
    "# ===============================================================================\n",
    "ImageId = [i+1 for i in range(len(test_svm_pred))]\n",
    "mainFileSubmit = pd.DataFrame({'ImageId':ImageId,'Label':(test_svm_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Creating CSV File of the dataset create above with 2 columns.\n",
    "# ===============================================================================\n",
    "mainFileSubmit.to_csv('FinalProject-Kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      4\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "#  This Cell Description\n",
    "# ===============================================================================\n",
    "# Printing DataFrame.\n",
    "# ===============================================================================\n",
    "mainFileSubmit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Final Submission Result Image"
   ]
  },
  {
   "attachments": {
    "Kaggle-Submission-Result.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Kaggle-Submission-Result.PNG](attachment:Kaggle-Submission-Result.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
